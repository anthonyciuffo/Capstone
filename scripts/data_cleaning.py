# -*- coding: utf-8 -*-
"""Data Cleaning and Merging Script

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Th7NdNy25XF6LZQ71-5SmL0rp9VzNlPL
"""

import pandas as pd
import numpy as np
import os

def clean_numeric(x):
    """Helper to clean numeric strings."""
    if isinstance(x, str):
        clean = x.replace('$', '').replace(',', '').replace('â€ ', '').strip()
        if not clean or clean == '': return np.nan
        return pd.to_numeric(clean, errors='coerce')
    return x

def read_file_robust(filepath, **kwargs):
    """
    Tries to read a file as CSV first (even if extension is .xlsx).
    If that fails, tries Excel.
    IMPORTANT: Passes **kwargs (like skiprows) to both readers.
    """
    try:
        # Force comma delimiter just in case
        return pd.read_csv(filepath, **kwargs)
    except Exception:
        # If CSV reading fails, try Excel
        try:
            print(f"   (CSV read failed, trying Excel for {filepath})")

            return pd.read_excel(filepath, **kwargs)
        except Exception as e_xlsx:
            print(f"   ERROR reading {filepath}: {e_xlsx}")
            return None

def load_and_process_data():
    print("--- Starting Data Processing (Robust Version) ---")

    # --- FILE CONFIGURATION ---
    files = {
        'elsi': 'Raw_dsadas.xlsx',
        'poverty': 'Raw_Poverty2023.xlsx',
        'unemployment': 'Raw_Unemployment2023.xlsx',
        'education': 'Raw_Education2023.xlsx',
        'state_indicators': 'Raw_StateIndicatorsDatabase_2025.xlsx'
    }

    # Check existence before proceeding
    missing_files = [f for f in files.values() if not os.path.exists(f)]
    if missing_files:
        print("WARNING: The following files were not found in the current folder:")
        for f in missing_files:
            print(f" - {f}")
        print("Processing will attempt to continue with available files...")

    # ---------------------------------------------------------
    # 1. Load District Data (ELSI)
    # ---------------------------------------------------------
    print(f"\n1. Loading District Data: {files['elsi']}")

    df_district = None
    if os.path.exists(files['elsi']):

        df_district = read_file_robust(files['elsi'], header=6)

    if df_district is None:
        print("CRITICAL: Could not load ELSI District data. Aborting.")
        return

    # Clean Column Names
    df_district.columns = [str(c).split('[')[0].strip().replace('"', '') for c in df_district.columns]

    col_map = {
        'Agency Name': 'District_Name',
        'State Name': 'State_Full',
        'County Number': 'FIPS_Code',
        'Total Students': 'Total_Students',
        'Full-Time Equivalent': 'FTE_Teachers'
    }

    rename_dict = {}
    for col in df_district.columns:
        for key, val in col_map.items():
            if key in col:
                rename_dict[col] = val
                break

    df_district = df_district.rename(columns=rename_dict)

    # Clean metrics
    if 'Total_Students' in df_district.columns:
        df_district['Total_Students'] = df_district['Total_Students'].apply(clean_numeric)
    if 'FTE_Teachers' in df_district.columns:
        df_district['FTE_Teachers'] = df_district['FTE_Teachers'].apply(clean_numeric)
    if 'Total_Students' in df_district.columns and 'FTE_Teachers' in df_district.columns:
        df_district['Student_Teacher_Ratio'] = df_district['Total_Students'] / df_district['FTE_Teachers']

    if 'FIPS_Code' in df_district.columns:
        df_district['FIPS_Code'] = pd.to_numeric(df_district['FIPS_Code'], errors='coerce').astype('Int64').astype(str).str.zfill(5)

    print(f"   -> Loaded {len(df_district)} districts.")

    # ---------------------------------------------------------
    # 2. Load County Data (Poverty, Unemp, Edu)
    # ---------------------------------------------------------
    print("\n2. Loading County Data...")

    # --- Poverty ---
    df_pov = pd.DataFrame(columns=['FIPS_Code', 'State_Abbr'])
    if os.path.exists(files['poverty']):
        print(f"   Loading {files['poverty']}")

        temp_pov = read_file_robust(files['poverty'], skiprows=4)

        if temp_pov is not None:
            # Ensure FIPS column exists
            if 'FIPS_Code' in temp_pov.columns:
                temp_pov['FIPS_Code'] = pd.to_numeric(temp_pov['FIPS_Code'], errors='coerce').astype('Int64').astype(str).str.zfill(5)

                if 'PCTPOVALL_2023' in temp_pov.columns:
                    df_pov = temp_pov[['FIPS_Code', 'Stabr', 'PCTPOVALL_2023', 'MEDHHINC_2023']].rename(columns={
                        'PCTPOVALL_2023': 'Poverty_Rate',
                        'MEDHHINC_2023': 'Median_Household_Income',
                        'Stabr': 'State_Abbr'
                    })
            else:
                print(f"   ERROR: 'FIPS_Code' column not found in Poverty file. Columns found: {list(temp_pov.columns[:5])}")

    # --- Unemployment ---
    df_unemp = pd.DataFrame(columns=['FIPS_Code'])
    if os.path.exists(files['unemployment']):
        print(f"   Loading {files['unemployment']}")
        temp_unemp = read_file_robust(files['unemployment'], skiprows=4)

        if temp_unemp is not None and 'FIPS_Code' in temp_unemp.columns:
            temp_unemp['FIPS_Code'] = pd.to_numeric(temp_unemp['FIPS_Code'], errors='coerce').astype('Int64').astype(str).str.zfill(5)
            if 'Unemployment_rate_2023' in temp_unemp.columns:
                df_unemp = temp_unemp[['FIPS_Code', 'Unemployment_rate_2023']].rename(columns={'Unemployment_rate_2023': 'Unemployment_Rate'})

    # --- Education ---
    df_edu = pd.DataFrame(columns=['FIPS_Code'])
    if os.path.exists(files['education']):
        print(f"   Loading {files['education']}")
        temp_edu = read_file_robust(files['education'], skiprows=4)

        if temp_edu is not None:
            # Handle FIPS Code vs FIPS_Code variation
            fips_col = 'FIPS Code' if 'FIPS Code' in temp_edu.columns else 'FIPS_Code'

            if fips_col in temp_edu.columns:
                temp_edu[fips_col] = pd.to_numeric(temp_edu[fips_col], errors='coerce').astype('Int64').astype(str).str.zfill(5)
                temp_edu = temp_edu.rename(columns={fips_col: 'FIPS_Code'})

                # Search for Bachelor's degree column
                bach_col = [c for c in temp_edu.columns if "Bachelor" in c and "2019-23" in c and "Percent" in c]
                if bach_col:
                    df_edu = temp_edu[['FIPS_Code', bach_col[0]]].rename(columns={bach_col[0]: 'Percent_Bachelors'})

    # ---------------------------------------------------------
    # 3. Load State Indicators
    # ---------------------------------------------------------
    print("\n3. Loading State Indicators...")
    df_state_indicators = pd.DataFrame()
    if os.path.exists(files['state_indicators']):
        print(f"   Loading {files['state_indicators']}")

        df_si = read_file_robust(files['state_indicators'])

        if df_si is not None:
            if 'year' in df_si.columns:
                max_year = df_si['year'].max()
                df_si = df_si[df_si['year'] == max_year]

            cols_needed = ['stabbr', 'effort', 'predicted_strevpp0_']
            if all(c in df_si.columns for c in cols_needed):
                df_si = df_si[cols_needed].rename(columns={
                    'stabbr': 'State_Abbr',
                    'effort': 'State_Fiscal_Effort',
                    'predicted_strevpp0_': 'State_Revenue_Per_Pupil'
                })
                df_state_indicators = df_si

    # ---------------------------------------------------------
    # 4. Merge
    # ---------------------------------------------------------
    print("\n4. Merging Data...")

    # Merge county files
    df_county = df_pov.merge(df_unemp, on='FIPS_Code', how='outer')
    df_county = df_county.merge(df_edu, on='FIPS_Code', how='outer')

    # Merge state data
    if not df_state_indicators.empty and 'State_Abbr' in df_county.columns:
        df_county = df_county.merge(df_state_indicators, on='State_Abbr', how='left')

    # Merge onto District data
    df_final = df_district.merge(df_county, on='FIPS_Code', how='left')

    # ---------------------------------------------------------
    # 5. Final Cleanup
    # ---------------------------------------------------------
    if 'Graduation_Outcome' not in df_final.columns:
        # Categorical placeholder
        conditions = [
            (df_final['Poverty_Rate'] < 10),
            (df_final['Poverty_Rate'] >= 10) & (df_final['Poverty_Rate'] < 20),
            (df_final['Poverty_Rate'] >= 20)
        ]
        choices = ['High (>=90%)', 'Medium (80-89%)', 'Low (<80%)']
        df_final['Graduation_Outcome'] = np.select(conditions, choices, default='Unknown')

    df_final = df_final.dropna(subset=['District_Name'])

    output_file = 'Processed_Capstone_Data.csv'
    df_final.to_csv(output_file, index=False)
    print(f"\n--- SUCCESS: {output_file} created ---")
    print(f"Total Rows: {len(df_final)}")

if __name__ == "__main__":
    load_and_process_data()
